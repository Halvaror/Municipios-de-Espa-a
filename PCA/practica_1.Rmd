---
title: "Pr谩ctica I"
description: |
  An谩lisis de componentes principales
author:
  - name: C. Tangana (DNI 0000000-A)
    affiliation: Universidad Complutense de Madrid
    affiliation_url: 
date: "`r Sys.Date()`"
output:
    distill::distill_article:
        highlight: kate
        colorlinks: true
        code_folding: false
        toc: true            
        toc_depth: 3     
---

```{r setup, include = FALSE}
# Ajuste comunes de los chunk
knitr::opts_chunk$set(fig.width = 9, fig.asp = 1, out.width = "100%",
                      message = FALSE, warning = FALSE,
                      echo = TRUE, res = 400)
```

# Instrucciones (leer antes de empezar)

* Modifica dentro del documento `.Rmd` tus datos personales (nombre y DNI) ubicados en la cabecera del archivo.

* Aseg煤rate antes de seguir editando el documento que el archivo `.Rmd` compila (Knit) correctamente y se genera el `html` correspondiente.

* Los chunks creados est谩n o vac铆os o incompletos, de ah铆 que tengan la opci贸n `eval = FALSE`. Una vez que edites lo que consideres debes de cambiar a `eval = TRUE` para que los chunk se ejecuten

## Paquetes necesarios

Necesitaremos los siguientes paquetes:

```{r paquetes}
# Borramos variables del environment
rm(list = ls())
library(readxl)
library(skimr)
library(corrr)
library(corrplot)
library(ggforce)
library(ggthemes)
library(tidyverse)
library(tidymodels)
library(factoextra)
library(FactoMineR)
library(gridExtra)
```


# Carga de datos

El archivo de datos a usar ser谩 `distritos.xlsx`

```{r}
distritos <- read_xlsx(path = "./distritos.xlsx")
```

El fichero contiene **informaci贸n socioecon贸mica de los distritos de Madrid**

```{r}
glimpse(distritos)
```


Las variables recopilan la siguiente informaci贸n:

* `Distrito`: nombre del distrito
* `Superficie`: superficie del distrito (hect谩reas)
* `Densidad`: densidad de poblaci贸n
* `Pob_0_14`: proporci贸n de poblaci贸n menor de 14 a帽os
* `Pob_15_29`: proporci贸n de poblaci贸n de 15 a 29
* `Pob_30_44`: proporci贸n de poblaci贸n de 30 a 44
* `Pob_45_64`: proporci贸n de poblaci贸n de 45 a 64
* `Pob_65+`: proporci贸n de poblaci贸n de 65 o mas
* `N_Espa帽ola`: proporci贸n de poblaci贸n espa帽ola
* `Extranjeros`: proporci贸n de poblaci贸n extranjera
* `N_hogares`: n煤mero de hogares en miles
* `Renta`: renta media en miles
* `T_paro`: porcentaje de poblaci贸n parada
* `T_paro_H`: porcentaje de hombres parados
* `T_paro_M`: porcentaje de mujeres paradas
* `Paro_LD`: proporci贸n de poblaci贸n parada de larga duraci贸n
* `Analfabetos`: proporci贸n de poblaci贸n que no sabe leer ni escribir
* `Primaria_inc`: proporci贸n de poblaci贸n solo con estudios primarios
* `ESO`: proporci贸n de poblaci贸n solo ESO
* `fp_bach`: proporci贸n de poblaci贸n solo con FP o Bachillerato
* `T_medios`: proporci贸n de poblaci贸n Titulada media
* `T_superiores`: proporci贸n de poblaci贸n con estudios superiores
* `S_M2_vivienda`: superficie media de la vivienda
* `Valor_V`: valor catastral medio de la vivienda
* `Partido`: partido m谩s votado en las municipales 2019




# Ejercicio 1:


> Calcula los estad铆sticos b谩sicos de todas las variables con la funci贸n `skim()` del paquete `{skimr}`


```{r eval = TRUE}
# Completa el c贸digo y cambia a eval = TRUE 
skim(distritos) %>%
  tibble::as_tibble()
```

# Ejercicio 2

> Selecciona solo las variables num茅ricas

```{r eval = TRUE}
# Completa el c贸digo y cambia a eval = TRUE 
distritos_num <-
  distritos %>% select(where(is.numeric))
distritos_num
```

# Ejercicio 3

> Calcula la matriz de covarianzas (gu谩rdala en `cov_mat`)

```{r eval = TRUE}
# Completa el c贸digo y cambia a eval = TRUE 
cov_mat <-
  cov(distritos %>% select(where(is.numeric)))
cov_mat
```

> Calcula la matriz de correlaciones de forma num茅rica (gu谩rdala en `cor_mat`). Visualiza dicha matriz haciendo uso de `{corrplot}`. Responde adem谩s a las preguntas: 驴cu谩les son las variables m谩s correlacionadas (linealmente)? 驴C贸mo es el sentido de esa correlaci贸n?


```{r eval = TRUE}
# Completa el c贸digo y cambia a eval = TRUE 
cor_mat <-
  cor(distritos %>% select(where(is.numeric)))
cor_mat
```

```{r eval = FALSE}
# Completa el c贸digo y cambia a eval = TRUE 
corrplot(cor_mat, type = "upper",
         tl.col = "black",  method = "ellipse")
```

# Ejercicio 4

> Haciendo uso de `{ggplot2}`, representa los gr谩ficos de dispersi贸n de las variables T_paro (eje y) con relaci贸n a Analfabetos (eje x). Realiza un nuevo gr谩fico visualizando T_paro en relaci贸n a T_superiores. Comentar el sentido de las nubes de puntos, junto con las correlaciones obtenidas anteriormente. Personaliza el gr谩fico todo lo que puedas.

```{r eval = TRUE}
# Completa el c贸digo y cambia a eval = TRUE 
p1 <- ggplot(distritos, aes(y = T_paro, x = Analfabetos)) +
        geom_point(size = 3, alpha = 0.7, color='darkblue') +
        labs(y = "% Poblacin Parada", x = "% Poblacin Analfabeta",
             title = "Parados vs Analfabetos") +
        theme_minimal()
p1

```


```{r eval = TRUE}
# Completa el c贸digo y cambia a eval = TRUE 
p1 <- ggplot(distritos, aes(y = T_paro, x = Analfabetos)) +
        geom_point(size = 3, alpha = 0.7, color='darkblue') +
        labs(y = "% Poblacin Parada", x = "% Poblacin Analfabeta",
             title = "Proporcion de poblacin parada segn sus estudios") +
        theme_minimal()
p2 <- ggplot(distritos, aes(y = T_paro, x = T_superiores)) +
        geom_point(size = 3, alpha = 0.7) +
        labs(y = "", x = "% Poblacin con Estudios Superiores", title = "") +
        theme_minimal()
grid.arrange(p1, p2, nrow = 1)
# El paro aumenta a medida que el la proporcin de de poblacin analfabeta aumenta mientras que ocurre lo inverso con los estudios superiores. 
# Ambas variables estan correladas con T_paro como puede observarse en la matriz de correlaciones ya que que superan el 0.9 en sus cocientes de correlacin
```

# Ejercicio 5

> Haciendo uso de los paquetes `{FactoMineR}` y `{factoextra}`, realiza un an谩lisis de componentes principales y gu谩rdalo en el objeto `pca_fit`

```{r eval = TRUE}
# Completa el c贸digo y cambia a eval = TRUE 
pca_fit <- PCA(distritos_num, scale.unit = TRUE, ncp = 3, graph = FALSE)
```

## Ejercicio 5.1

> Obt茅n los autovalores asociados y detalla los resultados. 驴Cu谩nto explica la primera componente? 驴Cu谩nto explican las primeras 10 componentes? Si fij谩ramos un umbral de varianza explicada del 95%, 驴cu谩ntas componentes deber铆amos usar?

```{r eval = TRUE}
# Completa el c贸digo y cambia a eval = TRUE 
pca_fit$eig

# La primera componente explica el 52.11% de la varianza mientras que las 10 primeras explican el 99%. 
# Si queremos fijar el umbral de la varianza al 95 tendremos que usar las 7 primeras componentes. 
```

> Visualiza la varianza explicada por cada componente haciendo uso de `fviz_eig()`. Personaliza el gr谩fico todo lo que consideres

```{r eval = FALSE}
# Completa el c贸digo y cambia a eval = TRUE 

fviz_eig(pca_fit, addlabels = TRUE, barfill = "#A0EEAB", 
         barcolor = "#0D9A20", linecolor = "darkred", xlab = "Componentes",
         ylab = "% de varianza explicada", ncp = 15,
         main = "Varianza explicada por componentes",
         ggtheme = theme_minimal())
```

## Ejercicio 5.2

> Obt茅n los autovectores (por columnas). Escribe de manera expl铆cita la expresi贸n de la tres primeras componentes (como combinaci贸n lineal de las variables originales).


```{r eval = FALSE}
# Completa el c贸digo para obtener los loadings
pca_fit$svd$V
```

$$\Phi_1 = -0.044*Superficie^* - 0.050*Densidad^* + 0.055*Pob.0.menor.14^* + 0.167*Pob.25.39^*... $$
$$\Phi_2 = 0.23465060*Superficie^* -0.41402574*Densidad^* + 0.39016851*Pob.0.menor.14^* -0.23231478*Pob.25.39^*... $$
$$\Phi_3 = 0.456302477*Superficie^* -0.182077268*Densidad^* + 0.306165578*Pob.0.menor.14^* -0.128784859^*... $$

## Ejercicio 5.3

> Obt茅n las nuevas coordenadas (scores) de las observaciones proyectados en las nuevas direcciones


```{r eval = TRUE}
# Completa el c贸digo y cambia a eval = TRUE 
pca_fit$ind$coord
```


# Ejercicio 6

> Con el n煤mero de componentes (anteriormente determinado) que necesitamos para explicar al menos el 95% de varianza, repite el mismo an谩lisis que en el ejercicio 5.

```{r eval = TRUE}
# Completa el c贸digo y cambia a eval = TRUE
# Como vimos antes, necesitamos 7 componentes para explicar el 95% de la varianza
pca_fit <- PCA(distritos_num, scale.unit = TRUE, ncp = 7, graph = FALSE)

# Obtenemos los loadings
phi <- pca_fit$svd$V 

# Obtenemos las phi de las 7 variables
phi <- -phi
row.names(phi) <- c(colnames(distritos_num))
colnames(phi) <- c("Phi1", "Phi2", "Phi3", "Phi4", "Phi5", "Phi6", "Phi7")
phi

```

## Ejercicio 6.1 

> Ejecuta el c贸digo inferior y detalla cada una de las salidas. Detalla todo lo que consideres. En particular, 驴qu茅 distritos van a tener caracter铆sticas similares? Justifica la respuesta

```{r eval = TRUE}
# Cambia a eval = TRUE
coord <- pca_fit$ind$coord
coord <- as.data.frame(coord)
coord$distrito <- distritos$Distrito
library(grid)
grid.newpage()
grid.xaxis(at=coord$Dim.2, 
           vp=vpStack(viewport(height=unit(2,"lines")),
                      viewport(y=1, xscale = c(-5, 1.2), just="bottom")))
fviz_pca_ind(pca_fit, col.ind = "coord",
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"), 
             repel = TRUE) +
  theme_minimal() + 
  labs(title = "Coordenadas",
       color = "Peso")
pca_fit$ind$cos2
fviz_pca_ind(pca_fit, col.ind = "cos2",
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"), 
             repel = TRUE) +
  theme_minimal() + 
  labs(title = "Cos2",
       color = "Peso")
pca_fit$ind$contrib
fviz_pca_ind(pca_fit, col.ind = "contrib",
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"), 
             repel = TRUE) +
  theme_minimal() + 
  labs(title = "Contribucin",
       color = "Peso")
# Podemos vislumbrar que puede haber ciertos distritos con varias caracteristicas similares realizando unos graficos de los diferentes outputs vemos que se agrupan entre 3 a 7 grupos de nubes de puntos.
# Por lo tanto podemos decir que si que hay ciertos distritos con caractersticas similares. Es necesario hacer un analisis de clusteres mas en profundizar para llegar a una conclusin ms acertada.
# Tambin podemos ver individuos poco representados como CENTRO y TETUAN
```


## Ejercicio 6.2

> Ejecuta el c贸digo inferior y detalla cada una de las salidas. Detalla todo lo que consideres. En particular, 驴qu茅 variables van a estar mejor representadas (la informaci贸n que contienen) si hacemos uso solo de las 2 primeras componentes? Justifica tu respuesta

```{r eval = FALSE}
# Cambia a eval = TRUE
pca_fit$var$coord
pca_fit$var$cos2
pca_fit$var$contrib
```

# Ejercicio 7

> Realiza de nuevo el an谩lisis pero introduciendo todas las variables, incluyendo las cualitativas (sin que sean usadas en la construcci贸n de las nuevas direcciones pero que luego podamos obtener dichas variables proyectadas), con el n煤mero de componentes determinadas anteriormente para explicar el 95% de la varianza.

```{r eval = FALSE}
# Completa el c贸digo y cambia a eval = TRUE
```

## Ejercicio 7.1

> Ejecuta `fviz_pca_var()` para visualizar las variables respecto a las dos primeras componentes. Asigna el color de las flechas de tal manera que corresponda al m贸dulo (longitud) de la misma. Cambia la paleta de colores que usa para el gradiente de colores como consideres. Detalla todo lo que consideres, en concreto la correlaci贸n o independencia lineal de las variables. 驴Qu茅 variables tienen un comportamiento similar? 驴Cu谩les est谩n mejor representadas (usando solo las dos primeras componentes)? Prueba a usar tambi茅n `fviz_cos2()`

```{r eval = FALSE}
# Completa el c贸digo y cambia a eval = TRUE
col <- c("#00AFBB", "#E7B800", "#FC4E07")
fviz_pca_var(..., axes = ...,
             col.var = ...,
             gradient.cols = col)
```

## Ejercicio 7.2

> Ejecuta `fviz_pca_ind()` para visualizar a los distritos respecto a las dos primeras componentes. Usa la variable de partido para visualizar en dos colores distintos los individuos. 驴Qu茅 distritos tienen caracter铆sticas similares? Analiza todo lo que consideres

```{r eval = FALSE}
# Completa el c贸digo y cambia a eval = TRUE
fviz_pca_ind(..., axes = ..., habillage = ...)
```

## Ejercicio 7.3

> Haciendo uso del gr谩fico anterior y de lo que consideres dentro de `pca_fit`, 驴qu茅 representar铆a (aprox) cada una de las primeras 3 componentes? 驴Qu茅 tipo de informaci贸n est谩 capturando cada una?

```{r eval = FALSE}
# Completa el c贸digo y cambia a eval = TRUE
```

## Ejercicio 7.4

> Haz uso de `fviz_pca_biplot()` para visualizar los dos gr谩ficos anteriores de forma conjunta y personaliza todo lo que consideres del gr谩fico. Detalla lo que consideres del gr谩fico y analiza los grupos de distritos creados en funci贸n del partido m谩s votado (le indicamos que el color dependa de dicha variable en `col.ind`)


```{r eval = FALSE}
# Completa el c贸digo y cambia a eval = FALSE
fviz_pca_biplot(pca_fit,
                col.ind = distritos$Partido,
                addEllipses = TRUE,
                label = "var",
                col.var = "black",
                repel = TRUE) +
  ...
```


# Ejercicio 8

> 驴Qu茅 valor tiene el distrito de Salamanca en la Componente 1? 驴Y Villaverde? 驴Qu茅 distrito tiene un valor m谩s alto de la Componente 4? Ejecuta el c贸digo que consideres

# Ejercicio 9

> Comenta/concluye todo lo que consideres tras un an谩lisis num茅rico y visual, y que no haya sido preguntado.

# Ejercicio 10 (extra)

> Haz uso de tidymodels para calcular las componentes y las 5 componentes que m谩s varianza capturan en una matriz de gr谩ficas (la diagonal la propia densidad de las componentes, fuera de la diagonal los datos proyectados en la componente (i,j)). Codifica el color como el partido m谩s votado. Al margen de la varianza explicada, 驴qu茅 par de componentes podr铆an servirnos mejor para 芦clasificar禄 nuestros barrios seg煤n el partido m谩s votado (variables que segmenten mejor mi espacio)?

```{r eval = FALSE}
# Completa el c贸digo
```



